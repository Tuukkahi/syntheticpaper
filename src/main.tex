\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage[numbers]{natbib}
\usepackage{geometry}
\geometry{margin=1in}

\title{Synthetic data trained neural network}
\author{}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

\begin{itemize}
\item     
    Satellite data with missing values or incomplete data. Retrospective reconstruction of time series. The task is to make forecasts or complete inclomplete historical data.

    \item
        Physics-constrained neural network
    \item
        Advection-(diffusion) model of dynamical systems.

        Assume simple advection diffusion dynamics. Solved numerically by (semi) Lagrangian schema. (aka warping). Using torch.grid.sample2d with nn interpolation. Some example of "warping".

        How about diffusion. Now it is not explicitly in the model. There is evident numerical diffusion, or is there? At least dimension reduction filter smooths the state. Kalman filter has spatially correlated model error that smooths the results, too.

        We do not model diffusion and in the COD example, the clouds do not diffuse(?). However, we might add small diffusion temp to the model in order to hide artefacts coming from numerics(?)

    \item
        Synthetic training data simulation

        Wee need data for training the model. One possibility is to simulate realistic data. Then we are not constrained by the amount of training data. But it is not clear  how well these model will perform.

    \item
        Dimension independence

        Advection fields are parameterized using 2d polynomial (or splines, etc). This makes the recontruction independent of the domain and discretization.

    \item
        Short-term prediction

        A practical application would be short term forecast, i.e., predicting the dynamics of the system a couple of time steps ahead. For the COD example, these could be used to predict solar energy production in the few coming hours. Similar models are used in many meteorological applications, for example short term rain forecasting using weather radar images.

    \item
        Spatio-temporal interpolation

        Interpolation of historical data to construct homogenized time series.

        
    \item
        Dimension reduction Kalman filter for posterior uncertainty

        Efficient algorithms utilizing PyTorch.

    \item Some example using COD data. Maybe some simple "baby" example first?

\end{itemize}







\section{Materials and methods}
\subsection{Advection-diffusion model}
Advection-diffusion equation
\begin{equation}
    \frac{\partial u}{\partial t} = F \cdot \nabla u + d \Delta u
\end{equation}

Leads to warping operator?


\subsection{Neural network model}
Neural networks have previously been used to predict pixel-wise values for full vector fields with the training objective being ground-truth vector fields~\cite{ofnn}, or warped images~\cite{debezenac}.
In high-noise real-world applications where the underlying vector fields are uniform, these methods provide noisy estimates of vector fields and thereby limiting their usefulness.
Our approach differs from this by parametrising the vector field using a low-dimensional basis, in this case a second degree polynomial
\begin{equation}
    P_2(x,y) = a_1 + a_2x + a_3y + a_4xy + a_5x^2+a_6y^2.
\end{equation}

For predicting the vector fields, we use a standard 28-layer convolutional ResNet neural network~\cite{resnet} originally developed for image recognition.

\subsection{Synthetic training data generation scheme}
In the absence of real-world datasets with ground-truth vector fields, we rely on synthetic training data to train our model.
By simulating data with a wide range of spatial structures, noise levels, and flow patterns, we aim at training a model that generalises beyond any specific data source.
Each synthetic sample is generated on demand during training, eliminating need for large dataset storage and providing a virtually unlimited supply of training data.

The synthetic data for each training sample is generated as follows:
\begin{enumerate}
    \item 
        \textbf{Initial Field Sampling}

        Initially we sample a random $\mathbb{R}^2$ field with the Matérn covariance
        \begin{equation}
            C_{\nu}(u,v) = \frac{2^{1-\nu}}{\Gamma(\nu)} (\frac{\sqrt{2\nu}}{\ell} \lVert u - v \rVert)^{\nu} K_{\nu}(\frac{\sqrt{2\nu}}{\ell} \lVert u - v \rVert)
        \end{equation}
        by solving spectrally the Matérn-Whittle stochastic partial differential equation (SPDE)~\cite{whittle63, lindgren}
        \begin{equation}
            (\kappa^2 - \Delta)^{\frac{\alpha}{2}} X(u) = W(u), \quad W \sim \mathcal{N}(0, I).
        \end{equation}

    \item 
        \textbf{Vector Field Sampling}

        A vector field is generated by sampling an integer magnitude within a specified range for each component of vectors at interpolation nodes.
        This is followed by a random global sign for each component to ensure diversity in all directions.
        The quadratic polynomial vector field is then solved, as descibed in~\ref{???}.
        These vector fields serves as the training objective for the model.

    \item
        \textbf{Numerical Advection and Noise Injection}

        The initial field is advected according to the generated vector field, creating a temporal sequence of images.
        At each step, small random integer perturbations are added to the vector fields to mimic dynamic variability of the vector fields and to show the network training data where advection is not strictly defined by quadratic polynomial vector fields.
        The target vector field in training remains the unperturbed quadratic one.

        In addition, at each step additive spatially correlated noise with sampled similarly as the initial field but with a random amplitude drawn between $[\sigma_{\text{min}}, \sigma_{\text{max}}]$.
        This exposes the neural network to a broad range of signal-to-noise ratios to enhances its robustness for real-world data.
\end{enumerate}
\subsection{Dimension reduction Kalman filter}
\cite{solonen}.

\subsection{COD}
\section{Results}


\section{Discussion}



\cite{de2019deep}

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
